# ğŸƒ Tresette AI

La nostra attivitÃ  progettuale per il corso di Fondamenti di Intelligenza Artificiale si Ã¨ basato sulla realizzazione di un sistema per la progettazione, lâ€™allenamento e la valutazione di unâ€™Intelligenza Artificiale capace di sfidare gli utenti al gioco di carte **Tresette**, tutto ciÃ² applicando tecniche di **Reinforcement Learning (RL)** e simulazioni di partite.

---

## ğŸ¯ Obiettivi

- **Modellare** le regole e le dinamiche del gioco del Tresette. -> Essere in grado di giocare contro un'AI non allenata(random)
- **Definire** un ambiente simulato in cui un agente AI possa giocare e migliorare.  -> Effettuare un training
- **Addestrare** lâ€™agente tramite algoritmi di *Deep Reinforcement Learning* (es. Deep Q-Learning).
- **Integrare** una componente **euristica** per migliorare lâ€™apprendimento. 
- **Permettere** a un giocatore umano di sfidare lâ€™AI.  
- **Confrontare** strategie casuali, euristiche e di apprendimento.  

---

## ğŸƒ Regole implementate

- Gestione del **mazzo** e distribuzione delle carte.  
- Turni di gioco per **4 giocatori** attraverso lista di mosse legali.  
- Calcolo delle **prese** e dei **punteggi** secondo le regole del Tresette. -> 1/3 per le figure , 1 per l'asso
- Definizione delle **condizioni di vittoria**.  

---

## ğŸ§  Architettura AI

- **Ambiente** â†’ rappresenta lo stato della partita (mani, prese, turno, carte giocate).  
- **Agente** â†’ apprende a selezionare le mosse tramite `Îµ-greedy policy`.  
- **Reward shaping** â†’ ricompense intermedie per prese utili e penalitÃ  per errori.  
- **Training loop** â†’ simulazione di migliaia di partite per ottimizzare la policy.  

---
## ğŸ‹ï¸â€â™‚ï¸ Training

Il processo di training dellâ€™agente segue due fasi principali:  

1. **Fase casuale** â†’ lâ€™agente gioca utilizzando mosse casuali, in modo da esplorare lo spazio delle possibilitÃ  e raccogliere esperienza.  
2. **Fase euristica** â†’ successivamente, viene introdotta una semplice euristica che guida le scelte dellâ€™agente (es. preferire mosse con carte forti o evitare sprechi), accelerando lâ€™apprendimento prima che intervenga lâ€™ottimizzazione tramite **Deep Q-Learning**.  

Durante il training:  
- Vengono salvati **checkpoint periodici** del modello, per poter riprendere lâ€™allenamento senza perdere i progressi.  
- Se disponibile, viene utilizzata la **GPU** tramite **PyTorch** per velocizzare il processo di apprendimento.  

 I parametri di training (es. numero di episodi, learning rate, epsilon decay, frequenza dei checkpoint) possono essere modificati direttamente nel file train_dqn.py.

Per avviare il training:  
```bash
python train_dqn.py
```
---

## ğŸ§© Architettura generale

Il sistema Ã¨ strutturato come un classico ambiente di **Reinforcement Learning**:  

| ğŸ§  **Agente** | Decide le mosse usando una `Îµ-greedy policy`. |
| ğŸ® **Ambiente** | Simula lo stato della partita (mani, prese, turno, carte giocate). |
| ğŸª™ **Reward shaping** | Ricompense intermedie per prese utili e penalitÃ  per errori. |
| ğŸ§© **Rete neurale (DQN)** | Stima i valori Q e apprende la policy ottimale. |
| ğŸ” **Replay Buffer** | Memorizza esperienze passate per stabilizzare lâ€™apprendimento. |
---

## ğŸ“‚ Struttura del progetto

```bash
Tresette_AI/
â”‚â”€â”€ cards.py           # Rappresentazione e utilitÃ  per le carte
â”‚â”€â”€ rules.py           # Regole del Tresette e calcolo dei punteggi
â”‚â”€â”€ game4p.py          # Logica del gioco a 4 giocatori e gestione dei turni
â”‚â”€â”€ encoder.py         # Conversione dello stato in feature numeriche
â”‚â”€â”€ train_dqn.py       # Addestramento tramite algoritmo Deep Q-Learning
â”‚â”€â”€ menu_cli.py        # Interfaccia a riga di comando per giocare contro lâ€™AI
â”‚â”€â”€ Watch_game.py      # Visualizzazione e replay delle partite
â”‚â”€â”€ obs/               # Moduli di osservazione e supporto
â”‚â”€â”€ tests/             # Test automatici e di integrazione
â””â”€â”€ README.md
```
---

## ğŸš€ Installazione

Per installare ed eseguire il progetto:

```bash
# 1. Clona la repository
git clone https://github.com/tuo-username/Tresette_AI.git
cd Tresette_AI

# 2. Crea e attiva un ambiente virtuale
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
.venv\Scripts\activate      # Windows

# 3. Installa le dipendenze
pip install -r requirements.txt

# 4. (Opzionale) Verifica il supporto GPU con PyTorch
python - <<EOF
import torch
print("CUDA disponibile:", torch.cuda.is_available())
EOF
```
---
## ğŸ® Giocare contro lâ€™AI

Dopo aver completato il training, Ã¨ possibile sfidare lâ€™agente tramite lâ€™interfaccia a riga di comando:

```bash
python menu_cli.py
```

Oppure osservare partite simulate:

```bash
python Watch_game.py
```

## ğŸ“¦ Requisiti

Il progetto richiede **Python 3.10+** e le seguenti librerie principali:

```txt
torch>=2.0.0
numpy>=1.23.0
matplotlib>=3.7.0
tqdm>=4.65.0
gym>=0.26.0
